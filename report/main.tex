\documentclass[1pt, a4paper]{article}

\input{structure.tex}


\begin{document}
\maketitlepage
\tableofcontents
\newpage
\section{Introduction}
\label{sec:intro}
\noindent
In quantum mechanics the eigenstates of an Hamiltonian are really important, especially the ground state. This state is the one that is the most populated and it's teh satrting point for the study of light-matter interaction. This program goals to find this ground state for any Hamiltonian by partially diagonalise the Hamiltonian. We will try to use the power iterative method and the Lanczos algorithm. This program was written in Fortran 95 under manjaro. There are 3 f95 files. The first one is \f{main.f95}, wich is the main file. If you want to add a new Hamiltonian or choose a method to diagonalise one, it's in this file. The second file is  \f{state.f95}, wich contains all the code for the power iterative method (in the subroutine \f{subroutine state}). You don't have to modify this file. And the third one is \f{lanczos.f95}, which contains the code for the Lanczos algorithm (in the subroutine \f{subroutine lanczos}). You don't have to modify this file but this part of the code don't work so you can try to improve it if you want. There is a file named \f{main} wich is the compile form of the program. You can find all these files on \href{https://github.com/faucheresse/fortran-swimming-pool.git}{github}.
\section{Functional requirement of the program}
\label{sec:2}
\noindent
In the main file, you can find the \f{program pool}. In this program there is the creation of Hamiltonians that we want to diagonalize and the called of subroutines for each method. There are already 3 functions for Hamiltonians. There is also an "Hamiltonian" named \f{test}, wich looks like an Hamiltonian for tests. So after creating the Hamiltonian wanted you can use the \f{subroutine main}, wich create initial data and call the \f{subroutine state}, or the \f{subroutine lanczos} or both.
\subsection{Hamiltonians}
\label{sub:ham}
\noindent
For this program we had created 3 functions for Hamiltonian. There are tables to describe them :
\begin{table}[htbp]
    \begin{center}
        \begin{tabular}{p{0.3\linewidth} p{0.3\linewidth} p{0.3\linewidth}} \toprule
            \multicolumn{3}{c}{\f{function H_2lvl(omega, phi, delta)}}\\
            \midrule
            \hfil Description & \hfil Input & \hfil Output\\
            \cmidrule(r){1-1} \cmidrule{2-2} \cmidrule(l){3-3}
           
            This function retrieve a Hamiltonian for a 2 level atom interacting with laser fields.&
            \vspace*{-8pt}
            \begin{itemize}[leftmargin=15pt, itemsep=0pt, topsep=0pt]
            \item \f{omega} : the laser amplitude multiplied by the atomic dipolar moment amplitude.
            \item \f{phi} : the laser phase.
            \item \f{delta} : the detuning.
            \end{itemize}
            &
            This function will retrieve a 2x2 matrix.\\
            \bottomrule
        \end{tabular}
    \end{center}
    \caption{\f{function H_2lvl}}
    \label{tab:H2lvl}
\end{table}
\newpage\noindent
\begin{table}[htbp]
    \begin{center}
        \begin{tabular}{p{0.3\linewidth} p{0.3\linewidth} p{0.3\linewidth}} \toprule
            \multicolumn{3}{c}{\f{function H_3lvl(omega_p, phi_p, delta_p, omega_s, phi_s, delta_s)}}\\
            \midrule
            \hfil Description & \hfil Input & \hfil Output\\
            \cmidrule(r){1-1} \cmidrule{2-2} \cmidrule(l){3-3}
           
            This function retrieve a Hamiltonian for a 3 level atom interacting with laser fields.&
            The "p" is for pump mode and "s" for Stokes mode.
            \begin{itemize}[leftmargin=15pt, itemsep=0pt, topsep=0pt]
            \item \f{omega_p/omega_s} : the laser amplitude multiplied by the atomic dipolar moment amplitude.
            \item \f{phi_p/phi_s} : the laser phase.
            \item \f{delta_p/delta_s} : the detuning.
            \end{itemize}
            &
            This function will retrieve a 3x3 matrix.\\
            \bottomrule
        \end{tabular}
    \end{center}
    \caption{\f{function H_2lvl}}
    \label{tab:H3lvl}
\end{table}
\begin{table}[htbp]
    \begin{center}
        \begin{tabular}{p{0.3\linewidth} p{0.3\linewidth} p{0.3\linewidth}} \toprule
            \multicolumn{3}{c}{\f{function molecular_H(N, L, m)}}\\
            \midrule
            \hfil Description & \hfil Input & \hfil Output\\
            \cmidrule(r){1-1} \cmidrule{2-2} \cmidrule(l){3-3}
           
            This function retrieve a molecular kinetic Hamiltonian.&
            \vspace*{-8pt}
            \begin{itemize}[leftmargin=15pt, itemsep=0pt, topsep=0pt]
            \item \f{N} : number of particle (size of the Hamiltonian)
            \item \f{L} : size of the molecule
            \item \f{m} : mass of the molecule
            \end{itemize}
            &
            This function will retrieve a NxN matrix, wich is diagonal.\\
            \bottomrule
        \end{tabular}
    \end{center}
    \caption{\f{function H_2lvl}}
    \label{tab:mol_H}
\end{table}
After using the \f{function molecular_H} you have to add to it the wanted potential to the kinetic Hamiltonian (all of them are commented under the example call). There are three different potatentials.
\begin{itemize}[leftmargin=15pt, itemsep=0pt, topsep=0pt]
    \item Particle in a box (\f{function box_potential(N, L)})
        \begin{equation}
            V(x) = \left\{\begin{array}{ll}
                            +\infty&if\;x=0\\
                            0\;\quad&if\;x\in ]0,L[\\
                            +\infty&if\;x=L
                          \end{array}\right.
        \end{equation}
    \item Harmonic oscillator (\f{function ho_potential(N, L, k)})
        \begin{equation}
            V(x) = \dfrac{1}{2}k\left(x - \dfrac{L}{2}\right)^2
        \end{equation}
    \item Vibration of the $H_2^+$ molecule (\f{function molecular_potential(N, L, V0, a)})
        \begin{equation}
            V(x) = V_0\left(\e^{-2a(x-x_0)} - 2\e^{a(x-x_0)}\right)
        \end{equation}
\end{itemize}
\newpage
\section{Internal structure of the program}
\label{sec:3}
\noindent
\subsection{Description of the diagonalization algorithms}
\label{sub:diag}
\noindent
\subsubsection{The power method algorithm}
\label{subs:pow}
\noindent
The power method algorithm consist to apply a matrix to a vector an infinite number of time. So to find the eigenvector we have :
\begin{equation}
\label{eq:eig}
    \ket{\phi_0} = H^{\infty}\ket{\psi}
\end{equation}
With $H$ the matrix we want to diagonalize, $\ket{\phi_0}$ the eigenvector ans $\ket{\psi}$ a random vector. So the associated eigenvalue, $\lambda_i$, is $\lambda_i = \Braket{\phi_0}{M}{\phi_0}$.\\
But we can't apply an infinite number of time a matrix to a vector. So we will transform a little the \autoref{eq:eig} and for the numerical calculation add a condition to stop before the infinity. We rewrite the \autoref{eq:eig} as :
\begin{equation}
    \lim_{k\rightarrow +\infty} \dfrac{H^k\ket{\psi}}{||H^k\ket{\psi}||} = \ket{\phi_0}
\end{equation}
In our case $H$ is a Hamiltonian, so it is a hermitian matrix with a negative spectrum. And we want to find the ground state which is the lowest eigenvalue of $H$. The lowest eigenvalue is $\lambda_0 = \Braket{\phi_0}{H}{\phi_0}$. So we will stop the computation when :
\begin{equation}
    ||H\ket{\phi_0} - \Braket{\phi_0}{H}{\phi_0}\ket{\phi_0}|| > \epsilon
\end{equation}
It is when the lowest eigenvalue it is a solution of the eigenequation for the ground state. With that we can write a pseudo-code to find the ground state.\\
\hrule
\noindent
\\
take a random vector $\phi_0$\\
normalize $\phi_0$\\
$H \leftarrow H - shift * id$\\
while $||H\phi_0 - \Braket{\phi_0}{H}{\phi 0}\phi_0|| > \epsilon$ and $k\leq k_{max}$ do\\
$\quad \phi_0 \leftarrow H\phi_0$\\
$\quad$ normalize $\phi_0$\\
$\quad k \leftarrow k + 1$\\
end while\\
$H \leftarrow H + shift * id$\\
$\lambda_0 \leftarrow \Braket{\phi_0}{H}{\phi_0}$\\
\hrule
\noindent
\\
$shift$ is a shift value to ensure a negative spectrum.\\
By using this method we can also find the first exited state by projecting onto an ortogonal component to avoid non-zero component from $\phi_0$ appearig into $\phi_1$. So we can write the following pseudo-code :\\
\hrule
\noindent
\\
take a random vector $\phi_1$\\
$\phi_1 \leftarrow \phi_1 - \braket{\phi_0}{\phi_1}\phi_0$\\
normalize $\phi_1$\\
$H \leftarrow H - shift * id$\\
while $||H\phi_0 - \Braket{\phi_1}{H}{\phi 1}\phi_1|| > \epsilon$ and $k\leq k_{max}$ do\\
$\quad \phi_1 \leftarrow H\phi_1$\\
$\quad\phi_1 \leftarrow \phi_1 - \braket{\phi_0}{\phi_1}\phi_0$\\
$\quad$ normalize $\phi_1$\\
$\quad k \leftarrow k + 1$\\
end while\\
$H \leftarrow H + shift * id$\\
$\lambda_1 \leftarrow \Braket{\phi_1}{H}{\phi_1}$\\
\hrule
\noindent
\newpage\noindent
After that $phi_0$ is the ground state and $\phi_1$ is the first exited state, $\lambda_0$ and $\lambda_1$ are the associated eigenvalues.
\subsubsection{The Lanczos algorithm}
\label{subs:lanczos}
\noindent
The Lanczos algorithm works onto tridiagonnal matrices so we project the Hamiltonian onto subspaces generated by the power iteration method. This subspaces are called krilov subspaces :
\[\mathcal{K}^n(H, \psi_0) = Lin(\psi_0, H\psi_0, H^2\psi_0, \hdots, H^{n-1}\psi_0)\]
We define the projection of $H$ into the Krilov subspace in the basis $\mathcal{B}^n$ (an orthonormal basis of $\mathcal{K}^n(H, \psi_0)$), as :
\begin{equation}
    \begin{aligned}
        H_{B^n} = \begin{pmatrix}
                    \alpha_0 & \bar{\beta}_1 & & 0\\
                    \beta_1 & \alpha_1 & \ddots & \\
                        & \ddots & \ddots & \bar{\beta}_{n-1}\\
                    0 & & \beta_{n-1} & \alpha_{n-1}
                  \end{pmatrix}
    \end{aligned}
\end{equation}
With $\alpha_i = \Braket{\psi_i}{H}{\psi_i}$ and $\beta_i = \Braket{\psi_{i+1}}{H}{\psi_i}$. The orthonormal basis $\mathcal{B}^n$ is define, using a modified Gram-Schmidt orthonormalization algorithm, as :
\begin{equation}
    \begin{aligned}
        \psi_1 &= \dfrac{\psi_1'}{||\psi_1'||}\qquad with\;\psi_1'=H\psi_0-\Braket{\psi_0}{H}{\psi_0}\psi_0\\
        \psi_i &= \dfrac{\psi_i'}{||\psi_i'||}\qquad with\;\psi_i'=H\psi_{i-1}-\sum_{k=0}^{i-1}\Braket{\psi_k}{H}{\psi_{i-1}}\psi_k
    \end{aligned}
\end{equation}
After the projection we just have to use a direct diagonalisation of $H_{B^n}$. For a direct diagonalization we need to compute the caracteristic polynomial of $H_{B^n}$. To compute this polynomial we will use the following reccurence relation :
\begin{equation}
    \begin{aligned}
        p_0(\lambda) &= 1\\
        p_1(\lambda) &= \alpha_0-\lambda_0\\
        p_k(\lambda) &= (\alpha_{k-1}-\lambda)p_{k-1}(\lambda)-|\beta_{k-1}|^2p_{k-2}(\lambda)\quad\forall k\in\{2,\hdots,n\}
    \end{aligned}
\end{equation}
You can find the proof of this relation in \autoref{app:pol}. To find the lowest eigenvalue we will use a dichotomy algorithm that minimize the number of eigenvalues in an interval. So the goal is to reduce this interval by reducing the higher value in the interval and tighten it around the eigenvalue. There is the pseudo-code of this dichotomy :\\
\hrule
\noindent
\\
$b\leftarrow 0$\\
while $\omega(b)-\omega(a)\ne 1$ do $b\leftarrow (a + b)/2$\\
while $(b-a) > \epsilon$ do\\
$\quad$ if $\omega ((b+a)/2) - \omega(a) = 1$\\
$\qquad b\leftarrow (a + b)/2$\\
$\quad$ else\\
$\qquad a\leftarrow (a + b)/2$\\
$\quad$ end if\\
end while\\
$\lambda^{(n)}_0 \leftarrow (a + b) / 2$\\
\hrule
\noindent
\\
The function $\omega(\lambda)$ is the number of sign changes in the sequence $(p_k(\lambda))_{k\in \{0,\dots,n\}}$. The number of sign changes give the number of eigenvalues between $0$ and $\lambda$, because $\lambda$ is an eigenvalue if one element of the sequence $(p_k(\lambda))_{k\in \{0,\dots,n\}}$ is null, so when there is a sign change between two consecutives elements of this sequence that mean that there is an eigenvalue between them. So $\omega(b)-\omega(a)$ give the number of eigenvalues into $[a, b]$.\\
So the previous algorithm try to find the eigenvalue by tightening $[a, b]$ around it and keep only one eigenvalue. $b$ is null because we want a negative eigenvalue because we diagonalize a Hamiltonian. So $a$ as to be enough small.
 
\newpage\noindent
\section{Appendix}
\label{app:app}
\subsection{Proof of the relation for the caracteristic polynomial}
\label{app:pol}
This proof will be done by induction.\\
We have :
\begin{equation}
    \begin{aligned}
        p_0(\lambda) &= 1\\
        p_1(\lambda) &= \alpha_0-\lambda_0\\
    \end{aligned}
\end{equation}
And we want to prove the statement, $S(k)$ :
\begin{equation}
    p_k(\lambda) = (\alpha_{k-1}-\lambda)p_{k-1}(\lambda)-|\beta_{k-1}|^2p_{k-2}(\lambda)\quad\forall k\in\{2,\hdots,n\}
\end{equation}
\\
\underline{Base case :}\\
For $k=2$ :
\begin{equation}
    \begin{aligned}
            p_2(\lambda) = \left|\begin{matrix}
                                \alpha_0 - \lambda & \bar{\beta}_1\\
                                \beta_1 & \alpha_1 - \lambda
                            \end{matrix}\right| &= (\alpha_0-\lambda)(\alpha_1-\lambda) - |\beta_{k-2}|^2\\
                                                &= (\alpha_0-\lambda)(\alpha_1-\lambda) - |\beta_{k-2}|^2\times 1\\
                                                &= (\alpha_0-\lambda)p_1(\lambda) - |\beta_{k-2}|^2p_0(\lambda)\\
    \end{aligned}
\end{equation}
So the statement is true for $k=2$.\\
\\
\underline{Inductive step :}\\
We suppose that, for $k>2$, $S(k)$ and $S(k-1)$ are true.
\begin{equation}
    \begin{aligned}
        p_{k+1}(\lambda) &= \left|\begin{matrix}
                    \alpha_0-\lambda & \bar{\beta}_1 & & 0\\
                    \beta_1 & \alpha_1-\lambda & \ddots & \\
                        & \ddots & \ddots & \bar{\beta}_{k}\\
                    0 & & \beta_{k} & \alpha_{k}-\lambda
                  \end{matrix}\right|\\
                &= (-1)^{2k+1}\beta_k\left|\begin{matrix}
                                        \alpha_0-\lambda & \bar{\beta}_1 & & 0\\
                                        \beta_1 & \alpha_1-\lambda & \ddots & \\
                                            & \ddots & \ddots & \\
                                        0 & & \beta_{k-1} & \bar{\beta}_{k}
                                      \end{matrix}\right| + (-1)^{2k+2}(\alpha_k-\lambda)\left|\begin{matrix}
                                                                                \alpha_0-\lambda & \bar{\beta}_1 & & 0\\
                                                                                \beta_1 & \alpha_1-\lambda & \ddots & \\
                                                                                    & \ddots & \ddots & \bar{\beta}_{k-1}\\
                                                                                0 & & \beta_{k-1} & \alpha_{k-1}-\lambda
                                                                              \end{matrix}\right|\\
                &= (-1)^{4k+1}|\beta_k|^2\left|\begin{matrix}
                        \alpha_0-\lambda & \bar{\beta}_1 & & 0\\
                        \beta_1 & \alpha_1-\lambda & \ddots & \\
                            & \ddots & \ddots & \bar{\beta}_{k-2}\\
                        0 & & \beta_{k-2} & \alpha_{k-2}-\lambda
                      \end{matrix}\right| + (-1)^{2k+2}(\alpha_k-\lambda)\left|\begin{matrix}
                                                                \alpha_0-\lambda & \bar{\beta}_1 & & 0\\
                                                                \beta_1 & \alpha_1-\lambda & \ddots & \\
                                                                    & \ddots & \ddots & \bar{\beta}_{k-1}\\
                                                                0 & & \beta_{k-1} & \alpha_{k-1}-\lambda
                                                              \end{matrix}\right|\\
                &= (\alpha_k-\lambda)p_k(\lambda)-|\beta_k|^2p_{k-1}(\lambda)
    \end{aligned}
\end{equation}
That is, the statement $S(k+1)$ also holds true, establishing the inductive step.\\
\\
\underline{Conclusion}\\
Since both the base case and the inductive step have been proved as true, by mathematical induction the statement $S(k)$ holds for every natural number $k$.

% \begin{table}[htbp]
%     \begin{center}
%         \begin{tabular}{p{0.3\linewidth} p{0.3\linewidth} p{0.3\linewidth}} \toprule
%             \multicolumn{3}{c}{\py{name}}\\
%             \midrule
%             \hfil Description & \hfil Input & \hfil Output\\
%             \cmidrule(r){1-1} \cmidrule{2-2} \cmidrule(l){3-3}
           
%             This function computes the Shannon entropy over time of $\theta$. So for each vector of the list of vectors \py{theta}&
            % \vspace*{-8pt}
            % \begin{itemize}[leftmargin=15pt, itemsep=0pt, topsep=0pt]
                % \setlength{\itemsep}{0pt}
                % \item \py{"random"}
                % \item \py{"chimera"}
                % \item \py{"inverse"}
                % \item \py{"josephson"}
                % \end{itemize}
%             &
%             This function will retrieve two data files in the parameters directory.
%             \begin{itemize}[leftmargin=15pt, itemsep=0pt, topsep=0pt]
%                 \item \py{"S.dat"} : It contains a list of real of size T. \py{S} represents the Shannon entropy over time of each vector of \py{theta}
%             \end{itemize}\\
%             \bottomrule
%         \end{tabular}
%     \end{center}
%     \caption{function}
%     \label{tab:label}
% \end{table}

% \begin{figure}[htbp]
%     \centering
%     \includegraphics[width=.95\linewidth]{../outcomes/josephson/phase.png}
%     \caption{Complex mean of phase josephson arrays}
%     \label{fig:phase_j}
% \end{figure}

% \newpage
% \bibliographystyle{plain}
% \bibliography{biblio}
\end{document}